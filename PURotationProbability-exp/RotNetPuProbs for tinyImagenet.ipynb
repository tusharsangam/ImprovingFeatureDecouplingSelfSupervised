{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from GetDataLoaders import get_dataloaders, get_short_dataloaders\n",
    "from ImageNet_RotNet_AlexNet.AlexNet import AlexNet as AlexNetFeature\n",
    "from architectures.TransferLearningNet import Flatten\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "import time\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# we skip the probs for now\\ngama = 2.0\\nwith open(os.path.join(\"./PUprobs\", \\'prob.dat\\'), \\'r\\') as file_input:\\n    train_prob_str = file_input.readlines()\\n    train_prob = [float(i_prob_str.rstrip(\\'\\n\\')) for i_prob_str in train_prob_str]\\n    print(len(train_prob)/4.0)\\n    train_weight = [1.0 if 0==i%4 else 1-train_prob[i]**gama for i in range(len(train_prob))]\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# we skip the probs for now\n",
    "gama = 2.0\n",
    "with open(os.path.join(\"./PUprobs\", 'prob.dat'), 'r') as file_input:\n",
    "    train_prob_str = file_input.readlines()\n",
    "    train_prob = [float(i_prob_str.rstrip('\\n')) for i_prob_str in train_prob_str]\n",
    "    print(len(train_prob)/4.0)\n",
    "    train_weight = [1.0 if 0==i%4 else 1-train_prob[i]**gama for i in range(len(train_prob))]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, nChannels=256, num_classes=4, pool_size=6, pool_type='max'):\n",
    "        super(Classifier, self).__init__()\n",
    "        nChannelsAll = nChannels * pool_size * pool_size\n",
    "\n",
    "        layers = []\n",
    "        if pool_type == 'max':\n",
    "            layers.append(nn.AdaptiveMaxPool2d((pool_size, pool_size)))\n",
    "            #layers.append(nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        elif pool_type == 'avg':\n",
    "            layer.append(nn.AdaptiveAvgPool2d((pool_size, pool_size)))\n",
    "        layers.append(nn.BatchNorm2d(nChannels, affine=False))\n",
    "        layers.append(Flatten())\n",
    "        layers.append(nn.Linear(nChannelsAll, num_classes))\n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "        self.initilize()\n",
    "    \n",
    "    def forward(self, feat):\n",
    "        return self.classifier(feat)\n",
    "    def initilize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                fin = m.in_features\n",
    "                fout = m.out_features\n",
    "                std_val = np.sqrt(2.0/fout)\n",
    "                m.weight.data.normal_(0.0, std_val)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "batch_size = 192\n",
    "lr = 0.1\n",
    "LUT_lr = [(5, 0.01),(25, 0.002),(45, 0.0004),(65,0.00008)]\n",
    "num_epochs = 65\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "nesterov = True\n",
    "num_classes = 200\n",
    "loaders = get_dataloaders('imagenet', batch_size=batch_size, num_workers=2, unsupervised=False, simclr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_net = AlexNetFeature().to(device)\n",
    "#load pretrained weights in feature_net\n",
    "state_dict = torch.load(\"ImageNet_RotNet_AlexNet/model_net_epoch50\")\n",
    "feature_net.load_state_dict(state_dict['network'], strict=False)\n",
    "\n",
    "feature_net.eval()\n",
    "for param in feature_net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier_net = Classifier().to(device)\n",
    "classifier_optimizer = optim.SGD(classifier_net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=nesterov)\n",
    "Networks =   {'classifier':classifier_net}\n",
    "Optimizers = {'classifier':classifier_optimizer}\n",
    "\n",
    "Criterions = {'CE': nn.CrossEntropyLoss()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rates(epoch):\n",
    "    # filter out the networks that are not trainable and that do\n",
    "    # not have a learning rate Look Up Table (LUT_lr) in their optim_params\n",
    "    lr = next((lr for (max_epoch, lr) in LUT_lr if max_epoch>epoch), LUT_lr[-1][1])\n",
    "    for key in Optimizers:\n",
    "        for g in Optimizers[key].param_groups:\n",
    "            prev_lr = g['lr']\n",
    "            if prev_lr != lr:\n",
    "                print(\"Learning Rate Updated from {} to {}\".format(prev_lr, lr))\n",
    "                g['lr'] = lr\n",
    "\n",
    "def train_step(batch, train=True):\n",
    "    data, targets = batch\n",
    "    batch_size = targets.size(0)\n",
    "    \n",
    "    targets = torch.zeros(batch_size*4, dtype=torch.long, requires_grad=False)\n",
    "    targets[0 : batch_size] = 0\n",
    "    targets[batch_size*1 : batch_size*2] = 1\n",
    "    targets[batch_size*2 : batch_size*3] = 2\n",
    "    targets[batch_size*3 : batch_size*4] = 3\n",
    "    \n",
    "    #print(targets)\n",
    "    \n",
    "    if train is True:\n",
    "        for key in Optimizers:\n",
    "            Optimizers[key].zero_grad()\n",
    "    \n",
    "    #to cuda\n",
    "    \n",
    "    data, targets = data.to(device), targets.to(device)\n",
    "    \n",
    "    data_90 = torch.flip(torch.transpose(data,2,3),[2])\n",
    "    data_180 = torch.flip(torch.flip(data,[2]),[3])\n",
    "    data_270 = torch.transpose(torch.flip(data,[2]),2,3)\n",
    "    data = torch.stack([data, data_90, data_180, data_270], dim=1)\n",
    "    batch_size, rotations, channels, height, width = data.size()\n",
    "    data = data.view([batch_size*rotations, channels, height, width])\n",
    "   \n",
    "    data.requires_grad = False\n",
    "    \n",
    "    \n",
    "    #collect features\n",
    "    with torch.no_grad():\n",
    "        features = feature_net(data, ['conv5'])\n",
    "    \n",
    "    if train is False:\n",
    "        with torch.no_grad():\n",
    "            pred = Networks['classifier'](features)\n",
    "            #calculate loss\n",
    "            loss_cls =  Criterions['CE'](pred, targets)\n",
    "            \n",
    "    else:\n",
    "        pred = Networks['classifier'](features)\n",
    "        #calculate loss\n",
    "        loss_cls =  Criterions['CE'](pred, targets)\n",
    "    \n",
    "    if train is True:\n",
    "        loss_cls.backward()\n",
    "        for key in Optimizers:\n",
    "            Optimizers[key].step()\n",
    "    \n",
    "    #calculate classification accuracy\n",
    "    pred = F.softmax(pred, dim=1)\n",
    "    pred = pred.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(targets.view_as(pred)).sum().item()\n",
    "   \n",
    "    \n",
    "    return loss_cls.item(), correct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(data_loader, epoch, train=True):\n",
    "    mode = \"Train\" if train else \"Valid\"\n",
    "    if train is True:\n",
    "        for key in Networks:\n",
    "            Networks[key].train()\n",
    "    else:\n",
    "        for key in Networks:\n",
    "            Networks[key].eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    \n",
    "    if train:\n",
    "        adjust_learning_rates(epoch)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    tqdm_bar = tqdm(data_loader)\n",
    "    total_number = 0\n",
    "    for batch_idx, sample in enumerate(tqdm_bar):\n",
    "        \n",
    "        loss, correct_step = train_step(sample, train=train)\n",
    "        losses.append(loss)\n",
    "        correct += correct_step\n",
    "        total_number += sample[0].size(0)*4\n",
    "        tqdm_bar.set_description('{} Epoch: {} Loss: {:.6f}, Accuracy: {}/{} [{:.4f}%]'.format(mode, epoch, loss, correct, total_number, 100.0*(correct/total_number)))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Time for epoch pass {}\".format(end_time-start_time))\n",
    "    \n",
    "    loss = float(np.mean(losses))\n",
    "    acc =  float(correct / len(data_loader.dataset)*4)\n",
    "    print('{} set: Average loss: {:.4f}, Accuracy:{}/{} ({:.4f}%)\\n'.format(mode, loss, correct, len(data_loader.dataset)*4, 100.0*acc))\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def run_main_loop(loaders, num_epochs):\n",
    "    writer = SummaryWriter('logs/PUprobsfortinyimagenet')\n",
    "    save_path = \"weights/puclassifierfortinyimagenet.pth\"\n",
    "    best_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        #print(\"Performing {}th epoch\".format(epoch))\n",
    "        \n",
    "        train_loss, train_acc = train_validate(loaders['train_loader'], epoch, train=True)\n",
    "        val_loss, val_acc = train_validate(loaders['valid_loader'], epoch, train=False)\n",
    "    \n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Valid', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/Valid', val_acc, epoch)\n",
    "    \n",
    "        \n",
    "        if val_acc > best_acc  :\n",
    "            best_acc = val_acc\n",
    "            #save model\n",
    "            states = {\n",
    "                'epoch': epoch + 1,\n",
    "                'best_accuracy': best_acc\n",
    "            }\n",
    "            for key in Networks:\n",
    "                states[key+\"model\"] = Networks[key].state_dict()\n",
    "            for key in Optimizers:\n",
    "                states[key+\"optimizer\"] = Optimizers[key].state_dict()\n",
    "            torch.save(states, save_path)\n",
    "            print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate Updated from 0.1 to 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 Loss: 35.087143, Accuracy: 80143/320000 [25.0447%]: 100%|██████████| 417/417 [01:43<00:00,  4.03it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 103.55574607849121\n",
      "Train set: Average loss: 45.2970, Accuracy:80143/320000 (400.7150%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 0 Loss: 25.340919, Accuracy: 9959/40000 [24.8975%]: 100%|██████████| 53/53 [00:12<00:00,  4.17it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.701408863067627\n",
      "Valid set: Average loss: 36.1554, Accuracy:9959/40000 (398.3600%)\n",
      "\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Loss: 27.519411, Accuracy: 79992/320000 [24.9975%]: 100%|██████████| 417/417 [01:45<00:00,  3.97it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 105.14005279541016\n",
      "Train set: Average loss: 30.0772, Accuracy:79992/320000 (399.9600%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 1 Loss: 21.002329, Accuracy: 10027/40000 [25.0675%]: 100%|██████████| 53/53 [00:12<00:00,  4.13it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.826058626174927\n",
      "Valid set: Average loss: 26.1861, Accuracy:10027/40000 (401.0800%)\n",
      "\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 Loss: 18.932745, Accuracy: 80452/320000 [25.1412%]: 100%|██████████| 417/417 [01:45<00:00,  3.97it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 105.04572200775146\n",
      "Train set: Average loss: 22.1658, Accuracy:80452/320000 (402.2600%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 2 Loss: 15.775415, Accuracy: 10053/40000 [25.1325%]: 100%|██████████| 53/53 [00:13<00:00,  4.03it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 13.164636850357056\n",
      "Valid set: Average loss: 19.6141, Accuracy:10053/40000 (402.1200%)\n",
      "\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 Loss: 14.218469, Accuracy: 79961/320000 [24.9878%]: 100%|██████████| 417/417 [01:45<00:00,  3.96it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 105.17873477935791\n",
      "Train set: Average loss: 16.7865, Accuracy:79961/320000 (399.8050%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 3 Loss: 12.126490, Accuracy: 10027/40000 [25.0675%]: 100%|██████████| 53/53 [00:12<00:00,  4.13it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.820189476013184\n",
      "Valid set: Average loss: 14.8106, Accuracy:10027/40000 (401.0800%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Loss: 11.115479, Accuracy: 79872/320000 [24.9600%]: 100%|██████████| 417/417 [01:43<00:00,  4.02it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 103.80945563316345\n",
      "Train set: Average loss: 12.6930, Accuracy:79872/320000 (399.3600%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 4 Loss: 9.012389, Accuracy: 10034/40000 [25.0850%]: 100%|██████████| 53/53 [00:13<00:00,  4.01it/s] \n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 13.232436180114746\n",
      "Valid set: Average loss: 11.2040, Accuracy:10034/40000 (401.3600%)\n",
      "\n",
      "Learning Rate Updated from 0.01 to 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Loss: 10.050145, Accuracy: 80250/320000 [25.0781%]: 100%|██████████| 417/417 [01:44<00:00,  4.00it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 104.29106378555298\n",
      "Train set: Average loss: 10.4885, Accuracy:80250/320000 (401.2500%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 5 Loss: 7.869442, Accuracy: 10021/40000 [25.0525%]: 100%|██████████| 53/53 [00:12<00:00,  4.13it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.841731071472168\n",
      "Valid set: Average loss: 10.2905, Accuracy:10021/40000 (400.8400%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 Loss: 9.368963, Accuracy: 80201/320000 [25.0628%]: 100%|██████████| 417/417 [01:44<00:00,  4.00it/s] \n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 104.3473379611969\n",
      "Train set: Average loss: 9.8288, Accuracy:80201/320000 (401.0050%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 6 Loss: 7.550991, Accuracy: 10051/40000 [25.1275%]: 100%|██████████| 53/53 [00:12<00:00,  4.09it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.94724154472351\n",
      "Valid set: Average loss: 9.6639, Accuracy:10051/40000 (402.0400%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 Loss: 9.435275, Accuracy: 80080/320000 [25.0250%]: 100%|██████████| 417/417 [01:44<00:00,  3.97it/s] \n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 104.99618744850159\n",
      "Train set: Average loss: 9.2533, Accuracy:80080/320000 (400.4000%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 7 Loss: 6.939579, Accuracy: 10074/40000 [25.1850%]: 100%|██████████| 53/53 [00:12<00:00,  4.14it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.819048404693604\n",
      "Valid set: Average loss: 9.1088, Accuracy:10074/40000 (402.9600%)\n",
      "\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 Loss: 8.871571, Accuracy: 79701/320000 [24.9066%]: 100%|██████████| 417/417 [01:43<00:00,  4.03it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 103.5072557926178\n",
      "Train set: Average loss: 8.6989, Accuracy:79701/320000 (398.5050%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 8 Loss: 6.249327, Accuracy: 10022/40000 [25.0550%]: 100%|██████████| 53/53 [00:12<00:00,  4.16it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.757431268692017\n",
      "Valid set: Average loss: 8.5217, Accuracy:10022/40000 (400.8800%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 Loss: 8.306579, Accuracy: 80182/320000 [25.0569%]: 100%|██████████| 417/417 [01:44<00:00,  4.00it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 104.31588077545166\n",
      "Train set: Average loss: 8.1760, Accuracy:80182/320000 (400.9100%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 9 Loss: 6.087802, Accuracy: 9980/40000 [24.9500%]: 100%|██████████| 53/53 [00:12<00:00,  4.13it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.837442398071289\n",
      "Valid set: Average loss: 8.0630, Accuracy:9980/40000 (399.2000%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 Loss: 7.460752, Accuracy: 80032/320000 [25.0100%]: 100%|██████████| 417/417 [01:44<00:00,  4.01it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 104.10119199752808\n",
      "Train set: Average loss: 7.6656, Accuracy:80032/320000 (400.1600%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 10 Loss: 5.410100, Accuracy: 10087/40000 [25.2175%]: 100%|██████████| 53/53 [00:12<00:00,  4.12it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.872437477111816\n",
      "Valid set: Average loss: 7.5353, Accuracy:10087/40000 (403.4800%)\n",
      "\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 Loss: 6.983691, Accuracy: 80127/320000 [25.0397%]: 100%|██████████| 417/417 [01:45<00:00,  3.95it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 105.55942964553833\n",
      "Train set: Average loss: 7.1810, Accuracy:80127/320000 (400.6350%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 11 Loss: 5.538237, Accuracy: 10066/40000 [25.1650%]: 100%|██████████| 53/53 [00:12<00:00,  4.12it/s]\n",
      "  0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 12.872727394104004\n",
      "Valid set: Average loss: 7.0986, Accuracy:10066/40000 (402.6400%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 Loss: 6.841916, Accuracy: 80160/320000 [25.0500%]: 100%|██████████| 417/417 [01:45<00:00,  3.96it/s]\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch pass 105.17408347129822\n",
      "Train set: Average loss: 6.7404, Accuracy:80160/320000 (400.8000%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 12 Loss: 6.626887, Accuracy: 5559/22272 [24.9596%]:  55%|█████▍    | 29/53 [00:07<00:05,  4.32it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-62e80e28dcb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-ec70784ee102>\u001b[0m in \u001b[0;36mrun_main_loop\u001b[0;34m(loaders, num_epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_loader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ec70784ee102>\u001b[0m in \u001b[0;36mtrain_validate\u001b[0;34m(data_loader, epoch, train)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_main_loop(loaders, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = train_validate(loaders['test_loader'], 1, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
